{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c54b7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import skimage.io as skio\n",
    "\n",
    "from tqdm import tqdm\n",
    "from src.utils.dataset import DatasetSUPPORT_test_stitch, FrameReader,DatasetSUPPORT_incremental_load\n",
    "from model.SUPPORT import SUPPORT\n",
    "from src.utils.util import parse_arguments,get_coordinate_generator\n",
    "import argparse\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from src.utils.dataset import gen_train_dataloader, random_transform\n",
    "from src.utils.util import parse_arguments\n",
    "from model.SUPPORT import SUPPORT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f4fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, optimizer, rng, writer, epoch, opt):\n",
    "    \"\"\"\n",
    "    Train a model for a single epoch\n",
    "\n",
    "    Arguments:\n",
    "        train_dataloader: (Pytorch DataLoader)\n",
    "        model: (Pytorch nn.Module)\n",
    "        optimizer: (Pytorch optimzer)\n",
    "        rng: numpy random number generator\n",
    "        writer: (Tensorboard writer)\n",
    "        epoch: epoch of training (int)\n",
    "        opt: argparse dictionary\n",
    "\n",
    "    Returns:\n",
    "        loss_list: list of total loss of each batch ([float])\n",
    "        loss_list_l1: list of L1 loss of each batch ([float])\n",
    "        loss_list_l2: list of L2 loss of each batch ([float])\n",
    "        corr_list: list of correlation of each batch ([float])\n",
    "    \"\"\"\n",
    "\n",
    "    is_rotate = True if model.bs_size[0] == model.bs_size[1] else False\n",
    "    \n",
    "    # initialize\n",
    "    model.train()\n",
    "    loss_list_l1 = []\n",
    "    loss_list_l2 = []\n",
    "    loss_list = []\n",
    "\n",
    "    L1_pixelwise = torch.nn.L1Loss()\n",
    "    L2_pixelwise = torch.nn.MSELoss()\n",
    "\n",
    "    loss_coef = opt.loss_coef\n",
    "\n",
    "    # training\n",
    "    for i, data in enumerate(tqdm(train_dataloader)):\n",
    "\n",
    "        (noisy_image, _, ds_idx) = data\n",
    "        noisy_image, _ = random_transform(noisy_image, None, rng, is_rotate)\n",
    "        \n",
    "        B, T, X, Y = noisy_image.shape\n",
    "        noisy_image = noisy_image.cuda()\n",
    "        noisy_image_target = torch.unsqueeze(noisy_image[:, int(T/2), :, :], dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        noisy_image_denoised = model(noisy_image)\n",
    "        loss_l1_pixelwise = L1_pixelwise(noisy_image_denoised, noisy_image_target)\n",
    "        loss_l2_pixelwise = L2_pixelwise(noisy_image_denoised, noisy_image_target)\n",
    "        loss_sum = loss_coef[0] * loss_l1_pixelwise + loss_coef[1] * loss_l2_pixelwise\n",
    "        loss_sum.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list_l1.append(loss_l1_pixelwise.item())\n",
    "        loss_list_l2.append(loss_l2_pixelwise.item())\n",
    "        loss_list.append(loss_sum.item())\n",
    "\n",
    "        # print log\n",
    "        if (epoch % opt.logging_interval == 0) and (i % opt.logging_interval_batch == 0):\n",
    "            loss_mean = np.mean(np.array(loss_list))\n",
    "            loss_mean_l1 = np.mean(np.array(loss_list_l1))\n",
    "            loss_mean_l2 = np.mean(np.array(loss_list_l2))\n",
    "\n",
    "            ts = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            writer.add_scalar(\"Loss_l1/train_batch\", loss_mean, epoch*len(train_dataloader) + i)\n",
    "            writer.add_scalar(\"Loss_l2/train_batch\", loss_mean_l1, epoch*len(train_dataloader) + i)\n",
    "            writer.add_scalar(\"Loss/train_batch\", loss_mean_l2, epoch*len(train_dataloader) + i)\n",
    "            \n",
    "            logging.info(f\"[{ts}] Epoch [{epoch}/{opt.n_epochs}] Batch [{i+1}/{len(train_dataloader)}] \"+\\\n",
    "                f\"loss : {loss_mean:.4f}, loss_l1 : {loss_mean_l1:.4f}, loss_l2 : {loss_mean_l2:.4f}\")\n",
    "\n",
    "    return loss_list, loss_list_l1, loss_list_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f46d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "numFramesToPred = 9\n",
    "opt = argparse.Namespace(random_seed=0,\n",
    "                         epoch=4,\n",
    "                         n_epochs=20,\n",
    "                         exp_name='mytest',\n",
    "                         results_dir='Y:\\\\WJC\\\\SUPPORT\\\\results',\n",
    "                         input_frames=numFramesToPred,\n",
    "                         is_folder=False,\n",
    "                         noisy_data=['E:\\\\20230621-162555\\\\FR00001_PV00001.raw'],\n",
    "                         patch_size=[numFramesToPred, 128, 128],\n",
    "                         patch_interval=[1, 64, 64],\n",
    "                         batch_size=16,\n",
    "                         totalFramesPerEpoch=10000,\n",
    "                         nConsecFrames=32,\n",
    "                         model='.\\\\results\\\\saved_models\\\\mytest\\\\model_6.pth',\n",
    "                         depth=5,\n",
    "                         blind_conv_channels=64,\n",
    "                         one_by_one_channels=[32, 16],\n",
    "                         last_layer_channels=[64, 32, 16],\n",
    "                         bs_size=[4, 4],\n",
    "                         bp=False,\n",
    "                         unet_channels=[16, 32, 64, 128, 256],\n",
    "                         lr=0.0005,\n",
    "                         loss_coef=[0.5, 0.5],\n",
    "                         use_CPU=False, n_cpu=8,\n",
    "                         logging_interval_batch=50,\n",
    "                         logging_interval=1,\n",
    "                         sample_interval=10,\n",
    "                         sample_max_t=600,\n",
    "                         checkpoint_interval=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d08bdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available() and (not opt.use_CPU)\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd649b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(random_seed=0, epoch=4, n_epochs=20, exp_name='mytest', results_dir='./results', input_frames=9, is_folder=False, noisy_data=['C:\\\\Voltage imaging\\\\20230621-162555\\\\FR00001_PV00001.raw'], patch_size=[9, 128, 128], patch_interval=[1, 64, 64], batch_size=16, totalFramesPerEpoch=10000, nConsecFrames=32, model='.\\\\results\\\\saved_models\\\\mytest\\\\model_6.pth', depth=5, blind_conv_channels=64, one_by_one_channels=[32, 16], last_layer_channels=[64, 32, 16], bs_size=[4, 4], bp=False, unet_channels=[16, 32, 64, 128, 256], lr=0.0005, loss_coef=[0.5, 0.5], use_CPU=False, n_cpu=8, logging_interval_batch=50, logging_interval=1, sample_interval=10, sample_max_t=600, checkpoint_interval=1)\n",
      "Loaded pre-trained model and optimizer weights of epoch 3\n",
      "=============== loading data ===============\n",
      "file 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading file 1: 100%|███████████████| 312/312 [00:11<00:00, 26.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== done loading ===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████▍                                                | 13655/37908 [16:04<28:08, 14.36it/s]"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ----------\n",
    "# Initialize: Create sample and checkpoint directories\n",
    "# ----------\n",
    "print(opt)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "rng = np.random.default_rng(opt.random_seed)\n",
    "\n",
    "os.makedirs(opt.results_dir + \"/images/{}\".format(opt.exp_name), exist_ok=True)\n",
    "os.makedirs(opt.results_dir + \"/saved_models/{}\".format(opt.exp_name), exist_ok=True)\n",
    "os.makedirs(opt.results_dir + \"/logs\".format(opt.exp_name), exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, filename=opt.results_dir + \"/logs/{}.log\".format(opt.exp_name),\\\n",
    "    filemode=\"a\", format=\"%(name)s - %(levelname)s - %(message)s\")\n",
    "writer = SummaryWriter(opt.results_dir + \"/tsboard/{}\".format(opt.exp_name))\n",
    "\n",
    "# ----------\n",
    "# Model, Optimizers, and Loss\n",
    "# ----------\n",
    "model = SUPPORT(in_channels=opt.input_frames, mid_channels=opt.unet_channels, depth=opt.depth,\\\n",
    "     blind_conv_channels=opt.blind_conv_channels, one_by_one_channels=opt.one_by_one_channels,\\\n",
    "            last_layer_channels=opt.last_layer_channels, bs_size=opt.bs_size, bp=opt.bp)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr)\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# print(opt.results_dir + \"/saved_models/%s/model_%d.pth\" % (opt.exp_name, opt.epoch-1))\n",
    "# exit()\n",
    "\n",
    "if opt.epoch != 0:\n",
    "    model.load_state_dict(torch.load(opt.results_dir + \"/saved_models/%s/model_%d.pth\" % (opt.exp_name, opt.epoch-1)))\n",
    "    optimizer.load_state_dict(torch.load(opt.results_dir + \"/saved_models/%s/optimizer_%d.pth\" % (opt.exp_name, opt.epoch-1)))\n",
    "    print('Loaded pre-trained model and optimizer weights of epoch {}'.format(opt.epoch-1))\n",
    "\n",
    "# ----------\n",
    "# Training & Validation\n",
    "# ----------\n",
    "for epoch in range(opt.epoch, opt.n_epochs):\n",
    "    #reload random parts of the data every epoch (when too large to fit all in memory)\n",
    "    dataloader_train = gen_train_dataloader(opt.patch_size, opt.patch_interval, opt.batch_size, \\\n",
    "        opt.noisy_data,totalFrames=opt.totalFramesPerEpoch,numConsecFrames=opt.nConsecFrames)\n",
    "\n",
    "    loss_list, loss_list_l1, loss_list_l2 =\\\n",
    "        train(dataloader_train, model, optimizer, rng, writer, epoch, opt)\n",
    "\n",
    "    # logging\n",
    "    ts = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "    if (epoch % opt.logging_interval == 0):\n",
    "        loss_mean = np.mean(np.array(loss_list))\n",
    "        loss_mean_l1 = np.mean(np.array(loss_list_l1))\n",
    "        loss_mean_l2 = np.mean(np.array(loss_list_l2))\n",
    "\n",
    "        writer.add_scalar(\"Loss/train\", loss_mean, epoch)\n",
    "        writer.add_scalar(\"Loss_l1/train\", loss_mean_l1, epoch)\n",
    "        writer.add_scalar(\"Loss_l2/train\", loss_mean_l2, epoch)\n",
    "        logging.info(f\"[{ts}] Epoch [{epoch}/{opt.n_epochs}] \"+\\\n",
    "            f\"loss : {loss_mean:.4f}, loss_l1 : {loss_mean_l1:.4f}, loss_l2 : {loss_mean_l2:.4f}\")\n",
    "\n",
    "    if (opt.checkpoint_interval != -1) and (epoch % opt.checkpoint_interval == 0):\n",
    "        model_loc = opt.results_dir + \"/saved_models/%s/model_%d.pth\" % (opt.exp_name, epoch)\n",
    "        torch.save(model.state_dict(), model_loc)\n",
    "        torch.save(optimizer.state_dict(), opt.results_dir + \"/saved_models/%s/optimizer_%d.pth\" % (opt.exp_name, epoch))\n",
    "\n",
    "    # if (epoch % opt.sample_interval == 0):\n",
    "    #     skio.imsave(opt.results_dir + \"/images/%s/denoised_%d.pth\" % (opt.exp_name, epoch), )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68bb5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(test_dataloader, model):\n",
    "    \"\"\"\n",
    "    Validate a model with a test data\n",
    "    \n",
    "    Arguments:\n",
    "        test_dataloader: (Pytorch DataLoader)\n",
    "            Should be DatasetFRECTAL_test_stitch!\n",
    "        model: (Pytorch nn.Module)\n",
    "\n",
    "    Returns:\n",
    "        denoised_stack: denoised image stack (Numpy array with dimension [T, X, Y])\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # initialize denoised stack to NaN array.\n",
    "        denoised_stack = np.zeros(test_dataloader.dataset.noisy_image.shape, dtype=np.float32)\n",
    "        \n",
    "        # stitching denoised stack\n",
    "        # insert the results if the stack value was NaN\n",
    "        # or, half of the output volume\n",
    "        for _, (noisy_image, _, single_coordinate,mean,std) in enumerate(tqdm(test_dataloader, desc=\"validate\")):\n",
    "            noisy_image = noisy_image.cuda() #[b, z, y, x]\n",
    "            noisy_image_denoised = model(noisy_image)\n",
    "            T = noisy_image.size(1)\n",
    "            for bi in range(noisy_image.size(0)): \n",
    "                stack_start_w = int(single_coordinate['stack_start_w'][bi])\n",
    "                stack_end_w = int(single_coordinate['stack_end_w'][bi])\n",
    "                patch_start_w = int(single_coordinate['patch_start_w'][bi])\n",
    "                patch_end_w = int(single_coordinate['patch_end_w'][bi])\n",
    "\n",
    "                stack_start_h = int(single_coordinate['stack_start_h'][bi])\n",
    "                stack_end_h = int(single_coordinate['stack_end_h'][bi])\n",
    "                patch_start_h = int(single_coordinate['patch_start_h'][bi])\n",
    "                patch_end_h = int(single_coordinate['patch_end_h'][bi])\n",
    "\n",
    "                stack_start_s = int(single_coordinate['init_s'][bi])\n",
    "                \n",
    "                denoised_stack[stack_start_s+(T//2), stack_start_h:stack_end_h, stack_start_w:stack_end_w] \\\n",
    "                    = (noisy_image_denoised[bi].squeeze()[patch_start_h:patch_end_h, patch_start_w:patch_end_w]*std+mean).cpu()\n",
    "\n",
    "        # change nan values to 0 and denormalize\n",
    "#         denoised_stack = denoised_stack * test_dataloader.dataset.std_image.numpy() + test_dataloader.dataset.mean_image.numpy()\n",
    "\n",
    "        return denoised_stack\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    \"\"\"\n",
    "    Normalize the image to [mean/std]=[0/1]\n",
    "\n",
    "    Arguments:\n",
    "        image: image stack (Pytorch Tensor with dimension [T, X, Y])\n",
    "\n",
    "    Returns:\n",
    "        image: normalized image stack (Pytorch Tensor with dimension [T, X, Y])\n",
    "        mean_image: mean of the image stack (np.float)\n",
    "        std_image: standard deviation of the image stack (np.float)\n",
    "    \"\"\"\n",
    "    mean_image = torch.mean(image)\n",
    "    std_image = torch.std(image)\n",
    "\n",
    "    image -= mean_image\n",
    "    image /= std_image\n",
    "\n",
    "    return image, mean_image, std_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d0fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "518b45b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(random_seed=0, epoch=0, n_epochs=5, exp_name='mytest', results_dir='./results', input_frames=9, is_folder=False, noisy_data=['C:\\\\Voltage imaging\\\\20230621-162555\\\\FR00001_PV00001.raw'], patch_size=[9, 128, 128], patch_interval=[1, 64, 64], batch_size=16, totalFramesPerEpoch=10000, nConsecFrames=32, model='.\\\\results\\\\saved_models\\\\mytest\\\\model_6.pth', depth=5, blind_conv_channels=64, one_by_one_channels=[32, 16], last_layer_channels=[64, 32, 16], bs_size=[4, 4], bp=False, unet_channels=[16, 32, 64, 128, 256], lr=0.0005, loss_coef=[0.5, 0.5], use_CPU=False, n_cpu=8, logging_interval_batch=50, logging_interval=1, sample_interval=10, sample_max_t=600, checkpoint_interval=1)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "print(opt)\n",
    "########## Change it with your data ##############\n",
    "data_file = opt.noisy_data[0]\n",
    "output_file = \"./results/denoised_0.h5\"\n",
    "patch_size = opt.patch_size\n",
    "patch_interval = [1, 32, 32]\n",
    "batch_size = 16    # lower it if memory exceeds.\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e566c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SUPPORT(in_channels=opt.input_frames, mid_channels=opt.unet_channels, depth=opt.depth,\\\n",
    "         blind_conv_channels=opt.blind_conv_channels, one_by_one_channels=opt.one_by_one_channels,\\\n",
    "                last_layer_channels=opt.last_layer_channels, bs_size=opt.bs_size, bp=opt.bp).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27b3d5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./results/saved_models/mytest/model_3.pth'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 3\n",
    "model_loc = opt.results_dir + \"/saved_models/%s/model_%d.pth\" % (opt.exp_name, epoch)\n",
    "model_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c9a17ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_file\n",
    "model.load_state_dict(torch.load(model_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27331e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd6187d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init: torch.Size([36, 624, 588])\n"
     ]
    }
   ],
   "source": [
    "reader = FrameReader(data_file,maxFrames=2400,width=588,height=624,gap=1728,shuffle=False)\n",
    "testset = DatasetSUPPORT_incremental_load(reader, patch_size=patch_size,\\\n",
    "    patch_interval=patch_interval)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10)\n",
    "test_dataloader = testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13f10e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2400, 624, 588])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_shape = test_dataloader.dataset.output_size\n",
    "stack_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97788a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Voltage imaging\\\\SUPPORT'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1f5e3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validate: 100%|██████████████████████████████████████████████████████████████████| 65063/65063 [22:11<00:00, 48.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tifffile import imwrite, memmap\n",
    "\n",
    "# with h5py.File(output_file, 'w') as hdf5_file:\n",
    "#     # create an HDF5 dataset to store the denoised stack\n",
    "#     denoised_stack = hdf5_file.create_dataset(\"denoised_stack\", stack_shape, dtype=np.uint8)\n",
    "with memmap(output_file, shape=stack_shape, dtype=np.uint8) as denoised_stack:\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # stitching denoised stack\n",
    "        for _, (noisy_image, _, single_coordinate) in enumerate(tqdm(test_dataloader, desc=\"validate\")):\n",
    "            \n",
    "            noisy_image, mean_image, std_image = normalize(noisy_image)\n",
    "            noisy_image = noisy_image.cuda() #[b, z, y, x]\n",
    "#             print(noisy_image.shape)\n",
    "            noisy_image_denoised = model(noisy_image)\n",
    "            T = noisy_image.size(1)\n",
    "            for bi in range(noisy_image.size(0)): \n",
    "                stack_start_w = int(single_coordinate['stack_start_w'][bi])\n",
    "                stack_end_w = int(single_coordinate['stack_end_w'][bi])\n",
    "                patch_start_w = int(single_coordinate['patch_start_w'][bi])\n",
    "                patch_end_w = int(single_coordinate['patch_end_w'][bi])\n",
    "\n",
    "                stack_start_h = int(single_coordinate['stack_start_h'][bi])\n",
    "                stack_end_h = int(single_coordinate['stack_end_h'][bi])\n",
    "                patch_start_h = int(single_coordinate['patch_start_h'][bi])\n",
    "                patch_end_h = int(single_coordinate['patch_end_h'][bi])\n",
    "\n",
    "                stack_start_s = int(single_coordinate['init_s'][bi])\n",
    "\n",
    "                denoised_stack[stack_start_s+(T//2), stack_start_h:stack_end_h, stack_start_w:stack_end_w] \\\n",
    "                    = (noisy_image_denoised[bi].squeeze()[patch_start_h:patch_end_h, patch_start_w:patch_end_w]*std_image + mean_image).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc14114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6aaeab3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wcunn\\AppData\\Local\\Temp\\ipykernel_1576\\399134675.py:7: DeprecationWarning: <tifffile.TiffWriter.save> is deprecated. Use TiffWriter.write\n",
      "  tiff.save(data[i])\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "with h5py.File(output_file, 'r') as h5_file:\n",
    "        data = h5_file[\"denoised_stack\"][:]\n",
    "\n",
    "with tifffile.TiffWriter(output_file+\".tif\", bigtiff=True) as tiff:\n",
    "    for i in range(data.shape[0]):\n",
    "        tiff.save(data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996daf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SUPPORT]",
   "language": "python",
   "name": "conda-env-SUPPORT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
